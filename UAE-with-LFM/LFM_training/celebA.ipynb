{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9773b26-6bef-4aed-b8f7-14ba52992e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/arf/home/tunal/ondemand/PhD Thesis Starting/01_SON/Tik-4/Tez/08-CelebA/05-UAE_Latent_FM\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd()) # dosya yolunu ver\n",
    "%run ../Model.ipynb\n",
    "%run ../Dataset.ipynb\n",
    "\n",
    "%run ./Flow_Model.ipynb\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c32132-3b3a-40ef-8c48-eba7f2aae31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters & Settings\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07121ef5-db8d-4bd5-a327-a8646f696809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yolu\n",
    "root_dir = '../data/img_align_celeba'\n",
    "\n",
    "train_dataset = CelebADataset(img_dir=root_dir, attr_path='../data/list_attr_celeba.csv', partition_path='../data/list_eval_partition.csv' , mode='train')\n",
    "val_dataset   = CelebADataset(img_dir=root_dir, attr_path='../data/list_attr_celeba.csv', partition_path='../data/list_eval_partition.csv', mode='val')\n",
    "test_dataset  = CelebADataset(img_dir=root_dir, attr_path='../data/list_attr_celeba.csv', partition_path='../data/list_eval_partition.csv', mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "test_loader  = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5796a6ef-999d-4f94-92bd-7bab72392f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "To_Uniform(\n",
       "  (encoder): SimpleEncoder(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (decoder): SimpleDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    )\n",
       "    (deconv1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (deconv2): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (deconv4): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (final_conv): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UAE modelini çalıştır\n",
    "\n",
    "path = '../ty/results/UAE_CelebA_HQ'\n",
    "model = torch.load(path + '.model', weights_only=False, map_location='cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a3ed17-bf58-4cad-9955-56b57f3c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"results\" klasörünü oluştur (zaten varsa hata vermez)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "flow_name = './results/UAE_Latent_FM'\n",
    "flow = Flow()\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 0.0003)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7496296a-6c85-41e4-8be4-5fb318216d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# --- 1. Veriyi encode et ---\n",
    "def get_encoded_loader(data_loader, encoder, device='cpu'):\n",
    "    encoder.eval()\n",
    "    encoded = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x in data_loader:\n",
    "            x = x.to(device)\n",
    "            z = encoder(x)\n",
    "            encoded.append(z.cpu())\n",
    "\n",
    "    all_z = torch.cat(encoded, dim=0)\n",
    "    return torch.utils.data.DataLoader(all_z, batch_size=data_loader.batch_size, shuffle=True)\n",
    "\n",
    "# --- 2. Encode edilmiş veri ile loader oluştur ---\n",
    "encoded_train_loader = get_encoded_loader(train_loader, model.encoder, device=device)\n",
    "encoded_val_loader = get_encoded_loader(val_loader, model.encoder, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f799e7d-6d3a-4717-babb-a3b58e5ea575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 10/1000 - Train Loss: 0.1121 - Val Loss: 0.1116\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 20/1000 - Train Loss: 0.1083 - Val Loss: 0.1080\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 30/1000 - Train Loss: 0.1057 - Val Loss: 0.1053\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 40/1000 - Train Loss: 0.1039 - Val Loss: 0.1035\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 50/1000 - Train Loss: 0.1025 - Val Loss: 0.1024\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 60/1000 - Train Loss: 0.1013 - Val Loss: 0.1012\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 70/1000 - Train Loss: 0.1004 - Val Loss: 0.1002\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 80/1000 - Train Loss: 0.0997 - Val Loss: 0.0994\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 90/1000 - Train Loss: 0.0989 - Val Loss: 0.0988\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 100/1000 - Train Loss: 0.0982 - Val Loss: 0.0980\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 110/1000 - Train Loss: 0.0977 - Val Loss: 0.0976\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 120/1000 - Train Loss: 0.0971 - Val Loss: 0.0967\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 130/1000 - Train Loss: 0.0966 - Val Loss: 0.0965\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 140/1000 - Train Loss: 0.0961 - Val Loss: 0.0961\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 150/1000 - Train Loss: 0.0958 - Val Loss: 0.0956\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 160/1000 - Train Loss: 0.0953 - Val Loss: 0.0952\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 170/1000 - Train Loss: 0.0950 - Val Loss: 0.0949\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 180/1000 - Train Loss: 0.0947 - Val Loss: 0.0947\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 190/1000 - Train Loss: 0.0943 - Val Loss: 0.0942\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 200/1000 - Train Loss: 0.0940 - Val Loss: 0.0939\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 210/1000 - Train Loss: 0.0938 - Val Loss: 0.0937\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 220/1000 - Train Loss: 0.0935 - Val Loss: 0.0935\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 230/1000 - Train Loss: 0.0932 - Val Loss: 0.0930\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 240/1000 - Train Loss: 0.0929 - Val Loss: 0.0928\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 250/1000 - Train Loss: 0.0927 - Val Loss: 0.0925\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 260/1000 - Train Loss: 0.0925 - Val Loss: 0.0924\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 270/1000 - Train Loss: 0.0923 - Val Loss: 0.0923\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 280/1000 - Train Loss: 0.0921 - Val Loss: 0.0920\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 290/1000 - Train Loss: 0.0919 - Val Loss: 0.0919\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 300/1000 - Train Loss: 0.0917 - Val Loss: 0.0918\n",
      "Saved!\n",
      "Epoch 310/1000 - Train Loss: 0.0916 - Val Loss: 0.0914\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 320/1000 - Train Loss: 0.0913 - Val Loss: 0.0915\n",
      "Saved!\n",
      "Epoch 330/1000 - Train Loss: 0.0912 - Val Loss: 0.0911\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 340/1000 - Train Loss: 0.0911 - Val Loss: 0.0910\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 350/1000 - Train Loss: 0.0909 - Val Loss: 0.0906\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 360/1000 - Train Loss: 0.0907 - Val Loss: 0.0907\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 370/1000 - Train Loss: 0.0906 - Val Loss: 0.0907\n",
      "Saved!\n",
      "Epoch 380/1000 - Train Loss: 0.0905 - Val Loss: 0.0905\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 390/1000 - Train Loss: 0.0903 - Val Loss: 0.0902\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 400/1000 - Train Loss: 0.0902 - Val Loss: 0.0902\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 410/1000 - Train Loss: 0.0901 - Val Loss: 0.0900\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 420/1000 - Train Loss: 0.0900 - Val Loss: 0.0899\n",
      "Saved!\n",
      "Epoch 430/1000 - Train Loss: 0.0899 - Val Loss: 0.0898\n",
      "Epoch 440/1000 - Train Loss: 0.0898 - Val Loss: 0.0896\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 450/1000 - Train Loss: 0.0896 - Val Loss: 0.0895\n",
      "Saved!\n",
      "Epoch 460/1000 - Train Loss: 0.0895 - Val Loss: 0.0897\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 470/1000 - Train Loss: 0.0894 - Val Loss: 0.0894\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 480/1000 - Train Loss: 0.0894 - Val Loss: 0.0894\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 490/1000 - Train Loss: 0.0893 - Val Loss: 0.0891\n",
      "Saved!\n",
      "Epoch 500/1000 - Train Loss: 0.0892 - Val Loss: 0.0891\n",
      "Saved!\n",
      "Epoch 510/1000 - Train Loss: 0.0891 - Val Loss: 0.0890\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 520/1000 - Train Loss: 0.0890 - Val Loss: 0.0890\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 530/1000 - Train Loss: 0.0889 - Val Loss: 0.0889\n",
      "Saved!\n",
      "Epoch 540/1000 - Train Loss: 0.0888 - Val Loss: 0.0889\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 550/1000 - Train Loss: 0.0888 - Val Loss: 0.0890\n",
      "Epoch 560/1000 - Train Loss: 0.0887 - Val Loss: 0.0885\n",
      "Saved!\n",
      "Epoch 570/1000 - Train Loss: 0.0886 - Val Loss: 0.0887\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 580/1000 - Train Loss: 0.0886 - Val Loss: 0.0886\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 590/1000 - Train Loss: 0.0885 - Val Loss: 0.0883\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 600/1000 - Train Loss: 0.0884 - Val Loss: 0.0883\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 610/1000 - Train Loss: 0.0883 - Val Loss: 0.0885\n",
      "Saved!\n",
      "Epoch 620/1000 - Train Loss: 0.0883 - Val Loss: 0.0883\n",
      "Epoch 630/1000 - Train Loss: 0.0882 - Val Loss: 0.0882\n",
      "Saved!\n",
      "Epoch 640/1000 - Train Loss: 0.0882 - Val Loss: 0.0881\n",
      "Epoch 650/1000 - Train Loss: 0.0882 - Val Loss: 0.0883\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 660/1000 - Train Loss: 0.0881 - Val Loss: 0.0881\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 670/1000 - Train Loss: 0.0880 - Val Loss: 0.0879\n",
      "Saved!\n",
      "Epoch 680/1000 - Train Loss: 0.0880 - Val Loss: 0.0879\n",
      "Saved!\n",
      "Epoch 690/1000 - Train Loss: 0.0880 - Val Loss: 0.0880\n",
      "Epoch 700/1000 - Train Loss: 0.0879 - Val Loss: 0.0880\n",
      "Epoch 710/1000 - Train Loss: 0.0879 - Val Loss: 0.0878\n",
      "Saved!\n",
      "Epoch 720/1000 - Train Loss: 0.0878 - Val Loss: 0.0876\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 730/1000 - Train Loss: 0.0878 - Val Loss: 0.0877\n",
      "Epoch 740/1000 - Train Loss: 0.0878 - Val Loss: 0.0879\n",
      "Saved!\n",
      "Epoch 750/1000 - Train Loss: 0.0877 - Val Loss: 0.0876\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 760/1000 - Train Loss: 0.0877 - Val Loss: 0.0875\n",
      "Saved!\n",
      "Epoch 770/1000 - Train Loss: 0.0877 - Val Loss: 0.0876\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 780/1000 - Train Loss: 0.0877 - Val Loss: 0.0877\n",
      "Saved!\n",
      "Epoch 790/1000 - Train Loss: 0.0875 - Val Loss: 0.0875\n",
      "Epoch 800/1000 - Train Loss: 0.0876 - Val Loss: 0.0877\n",
      "Saved!\n",
      "Epoch 810/1000 - Train Loss: 0.0875 - Val Loss: 0.0876\n",
      "Epoch 820/1000 - Train Loss: 0.0875 - Val Loss: 0.0876\n",
      "Epoch 830/1000 - Train Loss: 0.0875 - Val Loss: 0.0876\n",
      "Epoch 840/1000 - Train Loss: 0.0875 - Val Loss: 0.0874\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Flow Matching eğitimi ---\n",
    "train_cost = []\n",
    "val_cost = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1000):\n",
    "    epoch_losses = []\n",
    "\n",
    "    flow.train()\n",
    "    for z1 in encoded_train_loader:\n",
    "        z1 = z1.to(device)  # encode edilmiş temsil (batch_size x latent_dim)\n",
    "        z0 = torch.rand_like(z1)\n",
    "        t = torch.rand(len(z1), 1, device=device)\n",
    "\n",
    "        zt = (1 - t) * z0 + t * z1\n",
    "        dzt = z1 - z0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = flow(t=t, x_t=zt)\n",
    "        loss = loss_fn(pred, dzt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    mean_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_cost.append(mean_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    flow.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for z1_val in encoded_val_loader:\n",
    "            z1_val = z1_val.to(device)\n",
    "            z0_val = torch.rand_like(z1_val)\n",
    "            t_val = torch.rand(len(z1_val), 1, device=device)\n",
    "\n",
    "            zt_val = (1 - t_val) * z0_val + t_val * z1_val\n",
    "            dzt_val = z1_val - z0_val\n",
    "\n",
    "            pred_val = flow(t=t_val, x_t=zt_val)\n",
    "            val_loss = loss_fn(pred_val, dzt_val)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_cost.append(mean_val_loss)\n",
    "\n",
    "    # En iyi modeli kaydet\n",
    "    if mean_val_loss < best_val_loss:\n",
    "        print(\"Saved!\")\n",
    "        best_val_loss = mean_val_loss\n",
    "        torch.save(flow, flow_name + '.model')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/1000 - Train Loss: {mean_train_loss:.4f} - Val Loss: {mean_val_loss:.4f}\")\n",
    "\n",
    "# Son modeli kaydet\n",
    "torch.save(flow, flow_name + '_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59421793-1d36-443a-8b85-ba90b60402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasına kaydet\n",
    "train_losses = train_cost  # liste veya numpy array\n",
    "val_losses = val_cost\n",
    "\n",
    "np.savetxt(\"results/losses.csv\", \n",
    "           np.column_stack((train_losses, val_losses)), \n",
    "           delimiter=\",\", \n",
    "           header=\"train_loss,val_loss\", \n",
    "           comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbe9c5-093d-4c40-b3bd-8354c124fbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea62a7-5ab2-4b87-8b84-cbad856dd10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd93a6f-0503-42f5-9dc9-077fac3b16a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92307124-3c49-40f8-acd2-e6cac4ed42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada Eğitimin içinde veri encode ediliyor, bu yüzden çok yavaş çalışıyor\n",
    "\"\"\"\n",
    "train_cost = []\n",
    "val_cost = []\n",
    "best_val_loss = float('inf')  # Başlangıçta çok büyük bir değer\n",
    "\n",
    "for epoch in range(1000):\n",
    "    epoch_losses = []\n",
    "\n",
    "    flow.train()\n",
    "    for x in train_loader:\n",
    "\n",
    "        x_1 = model.encoder(x)  # encode edilmiş temsil (batch_size x latent_dim)\n",
    "        \n",
    "        x_0 = torch.rand_like(x_1)\n",
    "        t = torch.rand(len(x_1), 1)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = flow(t=t, x_t=x_t)\n",
    "        loss = loss_fn(pred, dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    mean_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_cost.append(mean_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    flow.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for x_val in val_loader:\n",
    "            x_1_val = model.encoder(x_val) # encode edilmiş temsil (batch_size x latent_dim)\n",
    "            \n",
    "            x_0_val = torch.rand_like(x_1_val)\n",
    "            t_val = torch.rand(len(x_1_val), 1)\n",
    "\n",
    "            x_t_val = (1 - t_val) * x_0_val + t_val * x_1_val\n",
    "            dx_t_val = x_1_val - x_0_val\n",
    "\n",
    "            pred_val = flow(t=t_val, x_t=x_t_val)\n",
    "            val_loss = loss_fn(pred_val, dx_t_val)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_cost.append(mean_val_loss)\n",
    "\n",
    "    # En iyi modeli val loss'a göre kaydet\n",
    "    if mean_val_loss < best_val_loss:\n",
    "        print('Saved!')\n",
    "        best_val_loss = mean_val_loss\n",
    "        torch.save(flow, flow_name + '.model')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/1000 - Train Loss: {mean_train_loss:.4f} - Val Loss: {mean_val_loss:.4f}\")\n",
    "\n",
    "# Son epoch modelini ayrı istersen:\n",
    "torch.save(flow, flow_name + '_final.model')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
