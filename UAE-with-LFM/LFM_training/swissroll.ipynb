{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9773b26-6bef-4aed-b8f7-14ba52992e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/arf/home/tunal/ondemand/PhD Thesis Starting/01_SON/Tik-4/Tez/02-SwissRoll/05-UAE_Latent_FlowMatching-Copy1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd()) # dosya yolunu ver\n",
    "%run ../02-UAE_for_SwissRoll/Model.ipynb\n",
    "%run ../Dataset.ipynb\n",
    "\n",
    "# Flow Model i çağır\n",
    "%run ./Flow_Model.ipynb\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6982ede7-a39e-433c-90a9-8850b1f73c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transform\n",
    "class NoiseTransform:\n",
    "    \"\"\"Add some noise.\"\"\"\n",
    "\n",
    "    def __init__(self, split_ratio=0.001, dim=3):\n",
    "\n",
    "        self.normal_dist = split_ratio*np.random.randn(dim,)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "      return x + self.normal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54c32132-3b3a-40ef-8c48-eba7f2aae31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters & Settings\n",
    "dataset_size = 10000\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07121ef5-db8d-4bd5-a327-a8646f696809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = SwissRollDataset(mode='train', n_samples=dataset_size)\n",
    "val_dataset = SwissRollDataset(mode='val', n_samples=dataset_size)\n",
    "test_dataset = SwissRollDataset(mode='test', n_samples=dataset_size)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5796a6ef-999d-4f94-92bd-7bab72392f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "To_Uniform(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): Linear(in_features=400, out_features=2, bias=True)\n",
       "    (16): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=400, out_features=3, bias=True)\n",
       "    (11): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UAE modelini çalıştır\n",
    "\n",
    "path = '../02-UAE_for_SwissRoll/results/UAE_SwissRoll'\n",
    "model = torch.load(path + '.model', weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64a3ed17-bf58-4cad-9955-56b57f3c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"results\" klasörünü oluştur (zaten varsa hata vermez)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "flow_name = './results/UAE_Latent_FlowMatching'\n",
    "flow = Flow()\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 0.001)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0d06e54-5399-4d78-bdb8-239ae15ff0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 1000/10000 - Train Loss: 0.1277 - Val Loss: 0.1268\n",
      "Epoch 2000/10000 - Train Loss: 0.1279 - Val Loss: 0.1225\n",
      "Saved!\n",
      "Epoch 3000/10000 - Train Loss: 0.1251 - Val Loss: 0.1282\n",
      "Epoch 4000/10000 - Train Loss: 0.1269 - Val Loss: 0.1259\n",
      "Epoch 5000/10000 - Train Loss: 0.1268 - Val Loss: 0.1233\n"
     ]
    }
   ],
   "source": [
    "train_cost = []\n",
    "val_cost = []\n",
    "best_val_loss = float('inf')  # Başlangıçta çok büyük bir değer\n",
    "\n",
    "for epoch in range(5000):\n",
    "    epoch_losses = []\n",
    "\n",
    "    flow.train()\n",
    "    for x, _ in train_loader:\n",
    "\n",
    "        x_1 = model.encoder(x)  # encode edilmiş temsil (batch_size x latent_dim)\n",
    "        \n",
    "        x_0 = torch.rand_like(x_1)\n",
    "        t = torch.rand(len(x_1), 1)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = flow(t=t, x_t=x_t)\n",
    "        loss = loss_fn(pred, dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    mean_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_cost.append(mean_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    flow.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for x_val, _ in val_loader:\n",
    "            x_1_val = model.encoder(x_val) # encode edilmiş temsil (batch_size x latent_dim)\n",
    "            \n",
    "            x_0_val = torch.rand_like(x_1_val)\n",
    "            t_val = torch.rand(len(x_1_val), 1)\n",
    "\n",
    "            x_t_val = (1 - t_val) * x_0_val + t_val * x_1_val\n",
    "            dx_t_val = x_1_val - x_0_val\n",
    "\n",
    "            pred_val = flow(t=t_val, x_t=x_t_val)\n",
    "            val_loss = loss_fn(pred_val, dx_t_val)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_cost.append(mean_val_loss)\n",
    "\n",
    "    # En iyi modeli val loss'a göre kaydet\n",
    "    if mean_val_loss < best_val_loss:\n",
    "        print('Saved!')\n",
    "        best_val_loss = mean_val_loss\n",
    "        torch.save(flow, flow_name + '.model')\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1}/10000 - Train Loss: {mean_train_loss:.4f} - Val Loss: {mean_val_loss:.4f}\")\n",
    "\n",
    "# Son epoch modelini ayrı istersen:\n",
    "torch.save(flow, flow_name + '_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46437271-96c6-4ad9-bec6-be4a325b7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasına kaydet\n",
    "train_losses = train_cost  # liste veya numpy array\n",
    "val_losses = val_cost\n",
    "\n",
    "np.savetxt(\"results/losses.csv\", \n",
    "           np.column_stack((train_losses, val_losses)), \n",
    "           delimiter=\",\", \n",
    "           header=\"train_loss,val_loss\", \n",
    "           comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d4dd3-44ea-4b6c-a6f3-060a0a535340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
