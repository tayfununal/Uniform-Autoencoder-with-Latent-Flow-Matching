{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9773b26-6bef-4aed-b8f7-14ba52992e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/arf/home/tunal/ondemand/PhD Thesis Starting/01_SON/Tik-4/Tez/05-MNIST/07-UAE_Latent_FM\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd()) # dosya yolunu ver\n",
    "%run ../Model.ipynb\n",
    "%run ../Dataset.ipynb\n",
    "\n",
    "%run ./Flow_Model.ipynb\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c32132-3b3a-40ef-8c48-eba7f2aae31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters & Settings\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07121ef5-db8d-4bd5-a327-a8646f696809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = MNISTDataset(mode='train')\n",
    "val_dataset = MNISTDataset(mode='val')\n",
    "test_dataset = MNISTDataset(mode='test')\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5796a6ef-999d-4f94-92bd-7bab72392f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "To_Uniform(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=2000, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (4): SiLU()\n",
       "    (5): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (10): SiLU()\n",
       "    (11): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=2000, out_features=3, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=2000, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=2000, out_features=784, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UAE modelini çalıştır\n",
    "\n",
    "path = '../02-UAE_for_MNIST/results/UAE_MNIST'\n",
    "model = torch.load(path + '.model', weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64a3ed17-bf58-4cad-9955-56b57f3c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"results\" klasörünü oluştur (zaten varsa hata vermez)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "flow_name = './results/UAE_Latent_FM'\n",
    "flow = Flow()\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 0.0003)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0d06e54-5399-4d78-bdb8-239ae15ff0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 100/1000 - Train Loss: 0.1142 - Val Loss: 0.1129\n",
      "Saved!\n",
      "Saved!\n",
      "Epoch 200/1000 - Train Loss: 0.1137 - Val Loss: 0.1126\n",
      "Epoch 300/1000 - Train Loss: 0.1141 - Val Loss: 0.1121\n",
      "Saved!\n",
      "Epoch 400/1000 - Train Loss: 0.1136 - Val Loss: 0.1135\n",
      "Epoch 500/1000 - Train Loss: 0.1141 - Val Loss: 0.1123\n",
      "Epoch 600/1000 - Train Loss: 0.1138 - Val Loss: 0.1115\n",
      "Saved!\n",
      "Epoch 700/1000 - Train Loss: 0.1138 - Val Loss: 0.1109\n",
      "Saved!\n",
      "Epoch 800/1000 - Train Loss: 0.1131 - Val Loss: 0.1126\n",
      "Saved!\n",
      "Epoch 900/1000 - Train Loss: 0.1134 - Val Loss: 0.1112\n",
      "Epoch 1000/1000 - Train Loss: 0.1133 - Val Loss: 0.1129\n"
     ]
    }
   ],
   "source": [
    "train_cost = []\n",
    "val_cost = []\n",
    "best_val_loss = float('inf')  # Başlangıçta çok büyük bir değer\n",
    "\n",
    "for epoch in range(1000):\n",
    "    epoch_losses = []\n",
    "\n",
    "    flow.train()\n",
    "    for x, _ in train_loader:\n",
    "\n",
    "        x_1 = model.encoder(x)  # encode edilmiş temsil (batch_size x latent_dim)\n",
    "        \n",
    "        x_0 = torch.rand_like(x_1)\n",
    "        t = torch.rand(len(x_1), 1)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = flow(t=t, x_t=x_t)\n",
    "        loss = loss_fn(pred, dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    mean_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_cost.append(mean_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    flow.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for x_val, _ in val_loader:\n",
    "            x_1_val = model.encoder(x_val) # encode edilmiş temsil (batch_size x latent_dim)\n",
    "            \n",
    "            x_0_val = torch.rand_like(x_1_val)\n",
    "            t_val = torch.rand(len(x_1_val), 1)\n",
    "\n",
    "            x_t_val = (1 - t_val) * x_0_val + t_val * x_1_val\n",
    "            dx_t_val = x_1_val - x_0_val\n",
    "\n",
    "            pred_val = flow(t=t_val, x_t=x_t_val)\n",
    "            val_loss = loss_fn(pred_val, dx_t_val)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_cost.append(mean_val_loss)\n",
    "\n",
    "    # En iyi modeli val loss'a göre kaydet\n",
    "    if mean_val_loss < best_val_loss:\n",
    "        print('Saved!')\n",
    "        best_val_loss = mean_val_loss\n",
    "        torch.save(flow, flow_name + '.model')\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/1000 - Train Loss: {mean_train_loss:.4f} - Val Loss: {mean_val_loss:.4f}\")\n",
    "\n",
    "# Son epoch modelini ayrı istersen:\n",
    "torch.save(flow, flow_name + '_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59421793-1d36-443a-8b85-ba90b60402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasına kaydet\n",
    "train_losses = train_cost  # liste veya numpy array\n",
    "val_losses = val_cost\n",
    "\n",
    "np.savetxt(\"results/losses.csv\", \n",
    "           np.column_stack((train_losses, val_losses)), \n",
    "           delimiter=\",\", \n",
    "           header=\"train_loss,val_loss\", \n",
    "           comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbe9c5-093d-4c40-b3bd-8354c124fbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
