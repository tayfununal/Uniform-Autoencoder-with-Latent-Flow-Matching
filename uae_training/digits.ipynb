{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/Uniform-Autoencoder-with-Latent-Flow-Matching/blob/main/uae_training/digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tayfununal/Uniform-Autoencoder-with-Latent-Flow-Matching.git"
      ],
      "metadata": {
        "id": "YdR9Tf9TaFvv"
      },
      "id": "YdR9Tf9TaFvv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9773b26-6bef-4aed-b8f7-14ba52992e30",
      "metadata": {
        "id": "c9773b26-6bef-4aed-b8f7-14ba52992e30"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "%run /content/Uniform-Autoencoder-with-Latent-Flow-Matching/datasets/digits_dataset.ipynb\n",
        "%run /content/Uniform-Autoencoder-with-Latent-Flow-Matching/models/digits_model.ipynb\n",
        "\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
        "plt.rcParams['font.serif'] = ['Times New Roman']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7601ea5-682f-44a9-9b06-0f0efd697f46",
      "metadata": {
        "id": "f7601ea5-682f-44a9-9b06-0f0efd697f46"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, device='cpu', max_patience=20):\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "        self.max_patience = max_patience\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.patience = 0\n",
        "\n",
        "        self.val_cost = []\n",
        "        self.train_cost = []\n",
        "\n",
        "    def train(self, train_loader, val_loader=None, epochs=10, print_every=1, name=None):\n",
        "        self.model.train()\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            total_loss = 0.0\n",
        "            for x, x_, _ in train_loader:\n",
        "                x = x.to(self.device)\n",
        "                x_ = x_.to(self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                  z_hat_, _ = self.model(x_)\n",
        "                z_hat, x_hat = self.model(x)\n",
        "\n",
        "                loss = self.model.criterion(z_pred=z_hat_, z_true=z_hat, x_pred=x_hat, x_true=x.reshape(-1,64))\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            # Validation\n",
        "            if val_loader:\n",
        "                val_loss = self.validate(val_loader)\n",
        "\n",
        "                # Early stopping check\n",
        "                if val_loss < self.best_val_loss:\n",
        "                    print('saved!')\n",
        "                    torch.save(self.model, name + '.model')\n",
        "                    self.best_val_loss = val_loss\n",
        "                    self.patience = 0\n",
        "\n",
        "                else:\n",
        "                    self.patience = self.patience + 1\n",
        "\n",
        "                if self.patience > self.max_patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "            if epoch % print_every == 0:\n",
        "                print(f\"Epoch {epoch:3d} | Train Loss: {total_loss / len(train_loader):.6f} | Validation Loss: {val_loss:.6f}\")\n",
        "\n",
        "            self.val_cost.append(val_loss)\n",
        "            self.train_cost.append(total_loss / len(train_loader))\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, x_, _ in val_loader:\n",
        "                x = x.to(self.device)\n",
        "                x_ = x_.to(self.device)\n",
        "\n",
        "\n",
        "                z_hat_, _ = self.model(x_)\n",
        "                z_hat, x_hat = self.model(x)\n",
        "\n",
        "                loss = self.model.criterion(z_pred=z_hat_, z_true=z_hat, x_pred=x_hat, x_true=x.reshape(-1,64))\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        self.model.train()\n",
        "        return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6982ede7-a39e-433c-90a9-8850b1f73c85",
      "metadata": {
        "id": "6982ede7-a39e-433c-90a9-8850b1f73c85"
      },
      "outputs": [],
      "source": [
        "# Custom Transform\n",
        "class NoiseTransform:\n",
        "    \"\"\"Add some noise.\"\"\"\n",
        "\n",
        "    def __init__(self, split_ratio=0.001, dim=64):\n",
        "\n",
        "        self.split_ratio = split_ratio\n",
        "        self.dim = dim\n",
        "\n",
        "    def __call__(self, x):\n",
        "      return x + self.split_ratio * torch.randn(self.dim, device='cuda' if torch.cuda.is_available() else 'cpu' , dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c32132-3b3a-40ef-8c48-eba7f2aae31f",
      "metadata": {
        "id": "54c32132-3b3a-40ef-8c48-eba7f2aae31f"
      },
      "outputs": [],
      "source": [
        "# Hyper-Parameters & Settings\n",
        "\n",
        "batch_size = 256\n",
        "lr = 0.0003\n",
        "\n",
        "epochs = 1000\n",
        "max_patience = 1000\n",
        "\n",
        "split_ratio = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07121ef5-db8d-4bd5-a327-a8646f696809",
      "metadata": {
        "id": "07121ef5-db8d-4bd5-a327-a8646f696809"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "train_dataset = DigitsDataset(mode='train', transform=NoiseTransform(split_ratio))\n",
        "val_dataset = DigitsDataset(mode='val', transform=NoiseTransform(split_ratio))\n",
        "test_dataset = DigitsDataset(mode='test')\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9abf79c-a874-418b-b46f-aaa2fe649d6e",
      "metadata": {
        "id": "c9abf79c-a874-418b-b46f-aaa2fe649d6e"
      },
      "outputs": [],
      "source": [
        "# Create the results folder\n",
        "os.makedirs(\"/content/Uniform-Autoencoder-with-Latent-Flow-Matching/results/digits\", exist_ok=True)\n",
        "\n",
        "# Model\n",
        "name = '/content/Uniform-Autoencoder-with-Latent-Flow-Matching/results/digits/UAE_Digits'\n",
        "model = UAE(\n",
        "            encoder_layers=[64, 512, 512, 512, 512, 3],\n",
        "            decoder_layers=[3, 512, 512, 512, 512, 64],\n",
        "            encoder_act=nn.SiLU,\n",
        "            decoder_act=nn.SiLU,\n",
        "            final_encoder_act=nn.Sigmoid,\n",
        "            final_decoder_act=nn.Sigmoid,\n",
        "            use_batchnorm=True\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d4bfd07-bccb-4b11-8d2d-3569e8fc0d48",
      "metadata": {
        "scrolled": true,
        "id": "8d4bfd07-bccb-4b11-8d2d-3569e8fc0d48"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "trainer = Trainer(model, optimizer, device='cuda' if torch.cuda.is_available() else 'cpu', max_patience=max_patience)\n",
        "trainer.train(train_loader, val_loader, epochs=epochs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbfbe84-b0ea-4aac-b097-1df904622beb",
      "metadata": {
        "id": "2cbfbe84-b0ea-4aac-b097-1df904622beb"
      },
      "outputs": [],
      "source": [
        "# Save to a CSV file\n",
        "train_losses = trainer.train_cost\n",
        "val_losses = trainer.val_cost\n",
        "\n",
        "np.savetxt(\"/content/Uniform-Autoencoder-with-Latent-Flow-Matching/results/digits/losses.csv\",\n",
        "           np.column_stack((train_losses, val_losses)),\n",
        "           delimiter=\",\",\n",
        "           header=\"train_loss,val_loss\",\n",
        "           comments=\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}